
services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"

  kowl:
    image: quay.io/cloudhut/kowl:master
    container_name: kowl
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_BROKERS: kafka:29092

  spark-master:
    image: apache/spark:4.0.1-scala2.13-java17-python3-r-ubuntu
    container_name: spark-master
    hostname: spark-master
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_NO_DAEMONIZE=true 
    ports:
      - "8081:8080"   # master WEB UI
      - "7077:7077"   # master port / Spark master RPC
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "--host", "0.0.0.0"]
    networks:
      - spark-net
  
  spark-worker:
    image: apache/spark:4.0.1-scala2.13-java17-python3-r-ubuntu
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1g
      - SPARK_NO_DAEMONIZE=true
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077", "--host", "0.0.0.0"]
    ports:
      - "8082:8081"
    networks:
      - spark-net

  clickhouse-server:
    image: clickhouse/clickhouse-server:24-alpine
    container_name: clickhouse-server
    ports:
      - "8123:8123"
      - "9000:9000"
    environment:
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    volumes:
      - ch_data:/var/lib/clickhouse
      - ch_logs:/var/log/clickhouse-server
      - ./services/clickhouse/init:/docker-entrypoint-initdb.d
    restart: unless-stopped
  
  data-generation:
    container_name: data-generation
    build:
      context: .
      dockerfile: ./services/data_generation/Dockerfile
    env_file:
      - ./services/data_generation/.env
    depends_on:
      - kafka


  spark-streaming:
    container_name: spark-streaming
    build:
      context: .
      dockerfile: ./services/spark/Dockerfile
    env_file:
      - ./services/spark/.env
    depends_on:
      - kafka
      - clickhouse-server
      - spark-master
      - spark-worker
  

  anomaly-prediction:
    container_name: anomaly-prediction
    build:
      context: .
      dockerfile: ./services/anomaly_prediction/Dockerfile
    env_file:
      - ./services/anomaly_prediction/.env
    depends_on:
      - kafka
      - clickhouse-server
      - spark-master
      - spark-worker
  
      
  grafana:
    image: grafana/grafana:12.3.0
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      GF_INSTALL_PLUGINS: grafana-clickhouse-datasource
    depends_on:
      - clickhouse-server
    volumes:
      - grafana-storage:/var/lib/grafana

volumes:
  postgres-db-volume:
  ch_data:
  ch_logs:
  grafana-storage:

networks:
  spark-net:
    driver: bridge